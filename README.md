<h2 align="center">
  Spotify ETL Data Pipeline on AWS <br/>
  <a href="https://github.com/prasanna-chintamaneni" target="_blank">By Naga Prasanna Chintamaneni</a>
</h2>

<div align="center">
  <img alt="AWS ETL Pipeline" src="D:\prasanna\Data Engineering Prep\Spotify-ETL-Data-Pipeline\Project Archicture.webpitecture.png">
</div>

<br/>

## ğŸ“Œ Project Overview  

In this project, I have built an **ETL (Extract, Transform, Load) pipeline** using the **Spotify API** on **AWS**.  
The pipeline automatically retrieves playlist data from Spotify, transforms it into a structured format, and loads it into AWS services for querying and analysis.  

The pipeline leverages:  
- **AWS Lambda** for serverless processing  
- **S3** as the data lake  
- **EventBridge** for scheduling automation  
- **AWS Glue** for cataloging data  
- **Athena** for running SQL queries on the processed dataset  

---

## ğŸš€ Built With  

This project was built using the following technologies:  

- **Python 3.9**  
- **Spotify Web API (Spotipy)** *(installed via AWS Lambda Layer)*  
- **AWS Lambda**  
- **Amazon S3**  
- **Amazon EventBridge**  
- **AWS Glue** (Crawlers & Data Catalog)  
- **Amazon Athena**  

---

## âš™ï¸ Architecture  

**1. Extract**  
- Spotify playlist data is extracted using the **Spotipy** library.  
- Implemented inside a Lambda function with API credentials stored securely in environment variables.  
- **Lambda Layer** is used to include external Spotipy dependency.  

**2. Transform**  
- Raw JSON is read from the S3 bucket.  
- Transformation Lambda parses track, album, and artist data into clean structured JSON files.  

**3. Load**  
- Transformed data is stored back in a separate S3 prefix (`processed/`).  
- AWS Glue Crawler is triggered to update the Data Catalog.  
- Amazon Athena is used to query structured Spotify data with SQL.  

---

## ğŸ›  Installation and Setup Instructions  

To run this project locally or deploy it to AWS:  

### 1ï¸âƒ£ Clone Repository  
git clone https://github.com/prasanna-chintamaneni/spotify-etl-pipeline.git
cd spotify-etl-pipeline

###2ï¸âƒ£ Create & Activate Virtual Environment
python -m venv venv
venv\Scripts\activate   # For Windows
source venv/bin/activate  # For Mac/Linux

###3ï¸âƒ£ Install Dependencies (for local testing)
pip install spotipy boto3

###4ï¸âƒ£ Prepare Lambda Layer (for Spotipy)
Since AWS Lambda does not include Spotipy by default, create a Lambda Layer:

mkdir python
pip install spotipy -t ./python
zip -r spotipy_layer.zip python

Upload spotipy_layer.zip in AWS Console â†’ Lambda â†’ Layers â†’ Create Layer.
Attach this layer to your Lambda function.

###5ï¸âƒ£ Configure AWS Credentials
Ensure IAM role has permissions for S3, Lambda, Glue, Athena.

###6ï¸âƒ£ Deploy Lambda Functions
Extract Lambda: Fetches data from Spotify API and uploads to raw_data/to_process/ in S3.
Transform Lambda: Cleans and restructures the raw data into albums, tracks, and artists, then stores in raw_data/processed/.

###7ï¸âƒ£ Set Up Automation
Create an EventBridge Rule to trigger the Extract Lambda periodically (e.g., every 1 hour/day).
Configure S3 Trigger for the Transform Lambda whenever new raw data is uploaded.

###8ï¸âƒ£ Data Querying
Use AWS Glue Crawler to scan the processed data and update the catalog.
Query datasets using Amazon Athena with SQL.

**ğŸ“Š Example Athena Query**
SELECT artist_name, COUNT(*) as track_count
FROM "spotify_database"."album_data"
GROUP BY artist_name
ORDER BY track_count DESC
LIMIT 10;

**âœ¨ Features**

Automated Data Extraction using EventBridge.

Serverless ETL Pipeline with AWS Lambda.

Data Lake Architecture using S3 (raw + processed layers).

Schema Discovery & Querying with Glue & Athena.

Scalable & Cost-Effective since it uses serverless components.

**ğŸ† Challenges & Solutions**

Challenge: AWS Lambda does not include external libraries like Spotipy.

Solution: Created a Lambda Layer with Spotipy dependency.

Challenge: Automating daily extraction from Spotify API.

Solution: Used EventBridge to schedule Lambda triggers.

Challenge: Converting messy Spotify JSON into structured data.

Solution: Wrote a transformation function to split data into Albums, Artists, and Tracks.

##ğŸ“‚ Project Structure
```bash
spotify-etl-data-pipeline/
â”‚
â”œâ”€â”€ functions/                         # Lambda functions
â”‚   â”œâ”€â”€ spotify-api-data-extraction/   # Extract function
â”‚   â””â”€â”€ spotify-transform/             # Transform & Load function
â”‚
â”œâ”€â”€ Layer/                             # Spotipy dependency packaged as Lambda Layer
â”‚   â””â”€â”€ spotipy_layer.zip
â”‚
â”œâ”€â”€ S3 Bucket (spotify-etl-project-np) # Data lake
â”‚   â”œâ”€â”€ raw_data/
â”‚   â”‚   â”œâ”€â”€ to_process/                # Raw JSON data from Spotify API
â”‚   â”‚   â””â”€â”€ processed/                 # Intermediate cleaned JSON
â”‚   â”‚
â”‚   â””â”€â”€ transformed_data/              # Final structured data
â”‚       â”œâ”€â”€ albums/                    # Album-level data
â”‚       â”œâ”€â”€ artists/                   # Artist-level data
â”‚       â””â”€â”€ songs/                     # Track-level data
â”‚
â””â”€â”€ README.md
